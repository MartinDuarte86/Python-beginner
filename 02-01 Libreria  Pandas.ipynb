{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"colab":{"name":"02-01 Libreria  Pandas.ipynb","provenance":[{"file_id":"1i6aGOJEr40DkIuE9C3J_Knk9o-u0iKA7","timestamp":1600879156057}]}},"cells":[{"cell_type":"markdown","metadata":{"id":"nVK2PJCBvBdv","colab_type":"text"},"source":["# <strong>Libreria Panda </strong>\n","Lee el datos de golpe y no carga una por una las filas de data frame, satura la memoria ram del ordenador \n","\n","<strong>Funciones generales</strong>\n"," \n","+ **.next()** (navega la siguiente posicion de la siguiente linea)\n","+ **.strip** (elimina los espacio blanco en el principio y al final de la linea)\n","+ **.split**(divide en columnas el archivo indicandole un delimitador ejemplo (\",\"))\n","+ **.readline** (lee solo una linea de df)[texto del vínculo](https://\n","\n","\n","\n"," \n"," \n"," \n"," \n","  \n"," \n"," "]},{"cell_type":"markdown","metadata":{"id":"OhiEPPCAxTJm","colab_type":"text"},"source":["\n","## <strong> Read.csv </strong>\n","1. **filepath** Url de donde esta cargado el archivo \n","+ . **Set** : Indica el separador de columna del CSV por defecto lo carga como \";\"\n","+ **dtype (\"A\":np.float64,\"B\":np.int32)** : Tipo de datos de las columnas del dataset, por default esta en 'none' toma el tipo de datos del archivo. \n","+ **header **  Cabecera del archivo (Forzar cabecera header=0)\n","+ **Name** renombrar las columnas\n","+ **skiprows ** empieza a cargar desde la fila indicada\n","+ **index_Col** Argumento numerico,renombrar etiquetas\n","+ **Skip_blank_lines** Booleano sirve para tratar las lineas en blanco, se inicia 100pre como False\n","    + *True* elimina las lineas en blancos \n","    + *False* No elimina las lineas y los identica como NaN\n","+ **na_filter** Boolean detectar los marcadores que faltan dentro del dataset \" \",Espacios en blancos,NaN. \n","    + *True* eliminan la fila del dataset \n","    + *False* Por default\n"]},{"cell_type":"markdown","metadata":{"id":"QN4suT7yxVks","colab_type":"text"},"source":["## Dataframe\n","\n","- **dataframe.columns.values** Veo el nombre de las columnas\n","- **dataframe[\"Column_Names\"]** seleccionar una determinada columna\n","- **dataframe[\"Column_Names\"].tolist()** seleccionar una determinada columna y transformarla en lista \"Siempre se debe transformar un dataframe en lista para poder trabajar\"\n","\n","\n"," "]},{"cell_type":"markdown","metadata":{"id":"_t_SnO0VzHcx","colab_type":"text"},"source":["### Practicas\n"]},{"cell_type":"markdown","metadata":{"id":"p4IcVicOxeUc","colab_type":"text"},"source":["####Unificar de dos dataset en uno tengo el encabezado y en otro las columnas\n","Ejercicio constata de cargar un archivo con los datos y con el otro archivo con los nombre de las columnas e indicarle la cabecera del dataframe apartir de segundo archivo .\n"]},{"cell_type":"code","metadata":{"id":"22IV9vT-xqIz","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":231},"executionInfo":{"status":"error","timestamp":1600878614054,"user_tz":180,"elapsed":1078,"user":{"displayName":"The T-tr","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GikGsgY53EWXLUvkLsxx8xRzFxQyZi2VtvDYOgX-A=s64","userId":"15991159013187081989"}},"outputId":"2f441248-145b-4cd3-958f-9811a4a6aef9"},"source":["# Indico la URL del archivo\n","#path =\"C:/Users/maeduart/Google Drive/Github/Curso_Python_Udemy/datasets_Test\"\n","filename=\"customer-churn-model/Customer Churn Model.txt\"\n","fullpath= os.path.join(path,filename)\n","\n","#Cargo las columnas en un dataframe y lo transformo en lista este detalle es importante, porque sino no lo podria \n","#asignarlo como \"Names\" (Nombre de columna) del segundo dataframe\n","Data_cols =pd.read_csv(path + \"/\" + \"customer-churn-model/Customer Churn Columns.csv\")\n","Data_columnas= Data_cols[\"Column_Names\"].tolist() ## .tolist() Super Importante\n","\n","\n","# No Cargo el header del archivo para asignarle atraves los nombres a las columnas atravez de la Funcion names asignandole\n","# el data_columnas para el nuevo nombre de las columnas\n","data2 = pd.read_csv(path + \"/\" + \"customer-churn-model/Customer Churn Model.txt\", \n","                    header = None, names = Data_columnas) \n","\n","# \"names = Data_columnas\" sirve para Asignar los valores del 1° dataframe, como nombre del columns de 2° dataframe \n","data2.columns.values\n","\n"],"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-c16f217154e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#path =\"C:/Users/maeduart/Google Drive/Github/Curso_Python_Udemy/datasets_Test\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"customer-churn-model/Customer Churn Model.txt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mfullpath\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#Cargo las columnas en un dataframe y lo transformo en lista este detalle es importante, porque sino no lo podria\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"]}]},{"cell_type":"markdown","metadata":{"id":"YjTulZSGvBeB","colab_type":"text"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"2HX1n9XkvBeG","colab_type":"text"},"source":["##Open\n","\n","**VENTAJAS**\n","+ Se utiliza cuando los archivos son muy grandes (+ 1 GB),porque lee linea por linea atravesz de un bucle y borra el alojamiento en memoria a medida que se va utlizando \n","+ el fichero se habre en modo lectura lee\n","+ puede ser guardado pedazo de dataset en diversos archivos y diferentes lugares e ir unificandos para trabajar todos juntos\n","\n","**Funciones open**\n","\n","+ **.open**([Ubicacion del archivo],\"w\")\n","    + r  = Lectura\n","    + rw = Lectura Escritura\n","    + w  =Escritura\n"]},{"cell_type":"markdown","metadata":{"id":"lrjZTrTdze0q","colab_type":"text"},"source":["### Practica\n"]},{"cell_type":"code","metadata":{"id":"ENAP9HvuvBeG","colab_type":"code","colab":{}},"source":["filename=\"customer-churn-model/Customer Churn Model.txt\"\n","fullpath= os.path.join(path,filename)\n","\n","#Cargo el dataset \n","Df_Funcion_open=open(fullpath,\"r\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5r9pyCm0vBeJ","colab_type":"code","colab":{}},"source":["#cargo solo el df con la primera linea con las columnas\n","cols=Df_Funcion_open.readline().strip().split(\",\")\n","#cuento la cantidad de columnas\n","n_cols=len(cols)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"k_ntBPnzxWec","colab_type":"text"},"source":["\n","## Lista de errores \n"," \n"," -  **SyntaxError: (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape**\n","     + Revisar que la barra no sea \\ para cargar un archivo solo acepta /"]},{"cell_type":"code","metadata":{"id":"GFR6lV5_vBeO","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}